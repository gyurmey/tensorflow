{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh9cH3DlJeYxVE1el4zi/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyurmey/tensorflow/blob/main/CNN/SEQUENTIAL/NOISE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEQUENTIAL CLASSIFIER:"
      ],
      "metadata": {
        "id": "aIyXfFm-Ynet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwrWV1M0YeXJ",
        "outputId": "86eac00a-f1d8-4849-a80b-17221f2afe72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2951 - accuracy: 0.9152\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1429 - accuracy: 0.9578\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1061 - accuracy: 0.9676\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.9733\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0731 - accuracy: 0.9769\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Precision: 0.9764\n",
            "Recall: 0.9764\n",
            "F1 score: 0.9764\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.99      0.99       980\n",
            "     class 1       0.99      0.99      0.99      1135\n",
            "     class 2       0.97      0.98      0.98      1032\n",
            "     class 3       0.98      0.96      0.97      1010\n",
            "     class 4       0.97      0.98      0.98       982\n",
            "     class 5       0.97      0.98      0.97       892\n",
            "     class 6       0.97      0.98      0.98       958\n",
            "     class 7       0.98      0.97      0.97      1028\n",
            "     class 8       0.98      0.97      0.97       974\n",
            "     class 9       0.98      0.95      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the sequential classifier model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_test, y_pred_classes, average='micro')\n",
        "recall = recall_score(y_test, y_pred_classes, average='micro')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='micro')\n",
        "\n",
        "# Print precision, recall, and F1 score\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Print classification report\n",
        "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9']\n",
        "print(classification_report(y_test, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN CLASSIFIER:\n",
        "\n",
        "This code defines and trains a convolutional neural network (CNN) to classify images of handwritten digits from the MNIST dataset. Here's what it does, step by step:\n",
        "\n",
        "Import the required libraries: TensorFlow and its Keras API, and the layers module from Keras. Load the MNIST dataset using the Keras API's mnist.load_data() function, which returns four NumPy arrays: x_train (the training images), y_train (the training labels), x_test (the test images), and y_test (the test labels). Normalize the pixel values of the images to be between 0 and 1 by dividing by 255.0. Reshape the images from 28x28 to 28x28x1 to match the input shape expected by the CNN. Define the CNN model using Keras' Sequential API, which allows you to stack layers one after another. The model consists of: a 2D convolutional layer with 32 filters, a 3x3 kernel size, and the ReLU activation function a 2D max pooling layer with a 2x2 pool size a 2D convolutional layer with 64 filters, a 3x3 kernel size, and the ReLU activation function another 2D max pooling layer with a 2x2 pool size a flatten layer to convert the output of the convolutional layers into a 1D vector a fully connected (dense) layer with 64 units and the ReLU activation function another fully connected layer with 10 units and the softmax activation function, which produces a probability distribution over the 10 classes (0-9). Compile the model by specifying the optimizer, the loss function, and the metrics to track during training. Here, we use the Adam optimizer, the sparse categorical cross-entropy loss function (which is appropriate for integer-encoded labels like the MNIST dataset), and track the accuracy metric. Train the model by calling the fit() method on the model object, passing in the training data and labels, and the number of epochs to train for (5). Evaluate the model on the test data using the evaluate() method, which returns the test loss and accuracy. Print the test accuracy. This code should train a model with around 99% test accuracy on the MNIST dataset."
      ],
      "metadata": {
        "id": "nRwnlXoIYjSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Reshape the data\n",
        "x_train = x_train.reshape((len(x_train), 28, 28, 1))\n",
        "x_test = x_test.reshape((len(x_test), 28, 28, 1))\n",
        "\n",
        "# Define the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "\n",
        "# Compute precision, recall, F1 score, and classification report\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1_score)\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwAXvg46YfCe",
        "outputId": "2e2ef324-048a-4d68-912e-9a5db72b4938"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1435 - accuracy: 0.9569\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0500 - accuracy: 0.9844\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0331 - accuracy: 0.9893\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0265 - accuracy: 0.9916\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0192 - accuracy: 0.9938\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9893\n",
            "Test accuracy: 0.989300012588501\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Precision: 0.9894051776749789\n",
            "Recall: 0.9890527482477331\n",
            "F1 score: 0.9892289315716309\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.98      1.00      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      1.00      0.99       982\n",
            "           5       0.99      0.98      0.98       892\n",
            "           6       1.00      0.98      0.99       958\n",
            "           7       0.99      0.98      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOISE:"
      ],
      "metadata": {
        "id": "QpClGYTrZG83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate noise with the same shape as the input images\n",
        "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
        "\n",
        "# Add noise to the input images\n",
        "x_test_noisy = x_test + noise\n",
        "\n",
        "# Clip the pixel values to the range [0, 1]\n",
        "x_test_noisy = np.clip(x_test_noisy, 0, 1)\n",
        "\n",
        "# Evaluate the model on the noisy images\n",
        "y_pred_noisy = model.predict(x_test_noisy)\n",
        "y_pred_classes_noisy = np.argmax(y_pred_noisy, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1 score on the noisy images\n",
        "precision_noisy = precision_score(y_test, y_pred_classes_noisy, average='micro')\n",
        "recall_noisy = recall_score(y_test, y_pred_classes_noisy, average='micro')\n",
        "f1_noisy = f1_score(y_test, y_pred_classes_noisy, average='micro')\n",
        "\n",
        "# Print precision, recall, and F1 score on the noisy images\n",
        "print(\"Precision (noisy):\", precision_noisy)\n",
        "print(\"Recall (noisy):\", recall_noisy)\n",
        "print(\"F1 score (noisy):\", f1_noisy)\n",
        "\n",
        "# Print classification report on the noisy images\n",
        "print(classification_report(y_test, y_pred_classes_noisy, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "iwX-TQgKY2QS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4634ba4-2c97-4e6b-d409-8ab5ffb22675"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Precision (noisy): 0.1639\n",
            "Recall (noisy): 0.1639\n",
            "F1 score (noisy): 0.1639\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.00      0.00      0.00       980\n",
            "     class 1       0.00      0.00      0.00      1135\n",
            "     class 2       0.18      0.90      0.30      1032\n",
            "     class 3       0.42      0.08      0.13      1010\n",
            "     class 4       0.00      0.00      0.00       982\n",
            "     class 5       0.13      0.68      0.22       892\n",
            "     class 6       0.89      0.03      0.05       958\n",
            "     class 7       1.00      0.00      0.00      1028\n",
            "     class 8       0.00      0.00      0.00       974\n",
            "     class 9       0.00      0.00      0.00      1009\n",
            "\n",
            "    accuracy                           0.16     10000\n",
            "   macro avg       0.26      0.17      0.07     10000\n",
            "weighted avg       0.26      0.16      0.07     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1YKJilOZH8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}